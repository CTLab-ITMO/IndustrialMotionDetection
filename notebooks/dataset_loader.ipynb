{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ruslan/src/IndustrialMotionDetection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslan/src/IndustrialMotionDetection/.venv/lib/python3.9/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/ruslan/src/IndustrialMotionDetection'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd ..\n",
    "%pwd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/usr/lib/python39.zip',\n",
       " '/usr/lib/python3.9',\n",
       " '/usr/lib/python3.9/lib-dynload',\n",
       " '',\n",
       " '/home/ruslan/src/IndustrialMotionDetection/.venv/lib/python3.9/site-packages',\n",
       " '/home/ruslan/src/IndustrialMotionDetection/src']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path().cwd().parent.absolute() / \"src\"))\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from models.dataset import RandomDatasetDecord\n",
    "from config import YamlConfigReader\n",
    "from models.dataset import collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_file_path = 'conf/meva_preproc.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'annotations_csv': 'data/MEVA/meva_processed/annotations.csv',\n",
       " 'train': 'data/MEVA/meva_processed/train.csv',\n",
       " 'test': 'data/MEVA/meva_processed/test.csv',\n",
       " 'annotations_folder': 'data/MEVA/meva-data-repo/annotation/DIVA-phase-2/MEVA/kitware-meva-training',\n",
       " 'bbox_area_limit': 10000,\n",
       " 'display_annotations': False,\n",
       " 'padding_frames': 30,\n",
       " 'result_folder': 'data/MEVA/meva_processed',\n",
       " 'split_seed': 42,\n",
       " 'target_activities': ['person_talks_on_phone',\n",
       "  'person_texts_on_phone',\n",
       "  'person_picks_up_object',\n",
       "  'person_reads_document',\n",
       "  'person_interacts_with_laptop'],\n",
       " 'test_size': 0.2,\n",
       " 'videos_root': 'data/MEVA/mevadata-public-01/drops-123-r13'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_source = YamlConfigReader(conf_file_path)\n",
    "params = config_source.get_all()\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'person_talks_on_phone': 0,\n",
       " 'person_texts_on_phone': 1,\n",
       " 'person_picks_up_object': 2,\n",
       " 'person_reads_document': 3,\n",
       " 'person_interacts_with_laptop': 4}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class2idx = {class_name: i for i, class_name in enumerate(params['target_activities'])}\n",
    "idx2class = {v: k for k, v in class2idx.items()}\n",
    "class2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = dict()\n",
    "image_datasets['test'] = RandomDatasetDecord(\n",
    "    params['test'],\n",
    "    class2idx=class2idx,\n",
    "    epoch_size_ratio=1.0,\n",
    "    video_transform=None,\n",
    "    frame_sample_rate=1.0,\n",
    "    clip_len=16,\n",
    "    num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_datasets['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d62b3c16624470a61e099e8fc0eec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/meva/2018-03-15/15/2018-03-15.15-10-00.15-15-00.bus.G331_frange0-5802.avi'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, x \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(image_datasets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m]), \n\u001b[1;32m      2\u001b[0m                  total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(image_datasets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m])):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m10\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/src/IndustrialMotionDetection/.venv/lib/python3.9/site-packages/tqdm/notebook.py:250\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    249\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 250\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/src/IndustrialMotionDetection/.venv/lib/python3.9/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/src/IndustrialMotionDetection/src/models/dataset.py:59\u001b[0m, in \u001b[0;36mRandomDatasetDecord.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m frames_per_second \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[1;32m     57\u001b[0m clip_duration \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_len \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe_sample_rate) \u001b[38;5;241m/\u001b[39m frames_per_second\n\u001b[0;32m---> 59\u001b[0m video \u001b[38;5;241m=\u001b[39m \u001b[43mEncodedVideo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# start_sec == 1, since 30 padding frames\u001b[39;00m\n\u001b[1;32m     62\u001b[0m offset_sec \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.4\u001b[39m\n",
      "File \u001b[0;32m~/src/IndustrialMotionDetection/.venv/lib/python3.9/site-packages/pytorchvideo/data/encoded_video.py:59\u001b[0m, in \u001b[0;36mEncodedVideo.from_path\u001b[0;34m(cls, file_path, decode_audio, decoder)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03mFetches the given video path using PathManager (allowing remote uris to be\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03mfetched) and constructs the EncodedVideo object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m    file_path (str): a PathManager file-path.\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# We read the file with PathManager so that we can read from remote uris.\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mg_pathmgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[1;32m     60\u001b[0m     video_file \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO(fh\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m     62\u001b[0m video_cls \u001b[38;5;241m=\u001b[39m select_video_class(decoder)\n",
      "File \u001b[0;32m~/src/IndustrialMotionDetection/.venv/lib/python3.9/site-packages/iopath/common/file_io.py:1062\u001b[0m, in \u001b[0;36mPathManager.open\u001b[0;34m(self, path, mode, buffering, **kwargs)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;66;03m# pass enable mode to handler that will be logging\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;66;03m# read, write operations separately.\u001b[39;00m\n\u001b[1;32m   1061\u001b[0m handler\u001b[38;5;241m.\u001b[39mset_logging(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_logging)\n\u001b[0;32m-> 1062\u001b[0m bret \u001b[38;5;241m=\u001b[39m \u001b[43mhandler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m kvs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_open_keys(path, mode, buffering)\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log_tmetry_keys(handler, kvs)\n",
      "File \u001b[0;32m~/src/IndustrialMotionDetection/.venv/lib/python3.9/site-packages/iopath/common/file_io.py:645\u001b[0m, in \u001b[0;36mNativePathHandler._open\u001b[0;34m(self, path, mode, buffering, encoding, errors, newline, closefd, opener, **kwargs)\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;124;03mOpen a path.\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;124;03m    file: a file-like object.\u001b[39;00m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_kwargs(kwargs)\n\u001b[0;32m--> 645\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_path_with_cwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnewline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosefd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopener\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopener\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/meva/2018-03-15/15/2018-03-15.15-10-00.15-15-00.bus.G331_frange0-5802.avi'"
     ]
    }
   ],
   "source": [
    "for i, x in tqdm(enumerate(image_datasets['test']), \n",
    "                 total=len(image_datasets['test'])):\n",
    "    if i == 1: break\n",
    "    print(x['video'].shape)\n",
    "    print(x['target'])\n",
    "    print(x['path'])\n",
    "    print(x['bbox'])\n",
    "    print()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2025\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(seed)\n",
    "\n",
    "dataloaders = dict()\n",
    "dataloaders['test'] = DataLoader(image_datasets['test'],\n",
    "                                 batch_size=batch_size,\n",
    "                                 pin_memory=True,\n",
    "                                 collate_fn=collate_fn,\n",
    "                                 worker_init_fn=seed_worker,\n",
    "                                 generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataloaders['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm_progress = tqdm(enumerate(dataloaders['test']), \n",
    "                     total=len(dataloaders['test']))\n",
    "\n",
    "for i, batch in tqdm_progress:\n",
    "    if i == 0:\n",
    "        print(f\"{batch['path']=}\\n{batch['video'].shape=}\")\n",
    "        first_video = batch['video'][0].permute(1, 0, 2, 3)\n",
    "        print(f\"{first_video.shape=}\")\n",
    "        print(f\"pixel range: {first_video.min()} - {first_video.max()}\")\n",
    "\n",
    "        print(f\"{len(batch['bbox'])=}\")\n",
    "        bbox_coords = batch['bbox'][0].bbox.tolist()\n",
    "        print(bbox_coords)\n",
    "\n",
    "        print(f\"{len(batch['target'])=}\")\n",
    "\n",
    "        fig, axes = plt.subplots(2, clip_len//2, figsize=(12, 12))\n",
    "\n",
    "        for i, ax in enumerate(axes.flat):\n",
    "            img = first_video[i].permute(1, 2, 0).numpy()\n",
    "            img = (img - img.min()) / (img.max() - img.min())\n",
    "\n",
    "            ax.imshow(img)\n",
    "            ax.axis('off')\n",
    "\n",
    "            for bbox_coord in bbox_coords:\n",
    "                x_min, y_min, x_max, y_max = bbox_coord\n",
    "                width = x_max - x_min\n",
    "                height = y_max - y_min\n",
    "                rect = patches.Rectangle((x_min, y_min), width, height,\n",
    "                                          linewidth=2, edgecolor='red', facecolor='none')\n",
    "                ax.add_patch(rect)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    break\n",
    "\n",
    "print(f\"Elapsed: {tqdm_progress.format_dict['elapsed']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
