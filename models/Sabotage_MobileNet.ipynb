{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrLfKh3zr0iK"
      },
      "outputs": [],
      "source": [
        "# @title Dataset, Dataloader\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "\n",
        "DATASET_PATH = '/content/drive/MyDrive/dataset'\n",
        "IMG_EXTENSIONS = ['.jpg', '.JPG', '.jpeg', '.JPEG']\n",
        "TRAIN_SIZE = 0.8\n",
        "MAX_DATASET_SIZE = 2000\n",
        "CLASS_TO_IDX = {\n",
        "    'normal': 0,\n",
        "    'moved': 1,\n",
        "    'covered': 2,\n",
        "    'defocussed': 3\n",
        "}\n",
        "\n",
        "\n",
        "def default_loader(path):\n",
        "    return Image.open(path).convert('RGB')\n",
        "\n",
        "\n",
        "def is_image_file(filename):\n",
        "    return any(filename.endswith(ext) for ext in IMG_EXTENSIONS)\n",
        "\n",
        "\n",
        "class SimpleDataset(Dataset):\n",
        "    def __init__(self, imgs, transform=None, loader=default_loader):\n",
        "        self.imgs = imgs\n",
        "        self.transform = transform\n",
        "        self.loader = loader\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        path, target = self.imgs[index]\n",
        "        img = self.loader(path)\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "\n",
        "def get_transformed_datasets(dir, transforms, max_class_size):\n",
        "    images = []\n",
        "\n",
        "    if not os.path.exists(dir):\n",
        "        raise FileNotFoundError(f\"Directory not found: {dir}\")\n",
        "\n",
        "    for target in os.listdir(dir):\n",
        "        if target not in CLASS_TO_IDX:\n",
        "            continue\n",
        "\n",
        "        d = os.path.join(dir, target)\n",
        "        if not os.path.isdir(d):\n",
        "            continue\n",
        "\n",
        "        for root, _, fnames in os.walk(d):\n",
        "            class_images = []\n",
        "            for fname in fnames:\n",
        "                if is_image_file(fname):\n",
        "                    path = os.path.join(root, fname)\n",
        "                    class_images.append((path, CLASS_TO_IDX[target]))\n",
        "            if len(class_images) < max_class_size:\n",
        "                print(f\"Requested {max_class_size} images per class. In class {target} only {len(class_images)}.\")\n",
        "                images.extend(class_images)\n",
        "            else:\n",
        "                images.extend(random.sample(class_images, max_class_size))\n",
        "\n",
        "    if not images:\n",
        "        raise RuntimeError(\n",
        "            f\"Found 0 images in subfolders of: {dir}\\n\"\n",
        "            f\"Supported extensions: {', '.join(IMG_EXTENSIONS)}\"\n",
        "        )\n",
        "\n",
        "    images_np = np.array(images, dtype=object)\n",
        "    np.random.shuffle(images_np)\n",
        "    split_idx = int(TRAIN_SIZE * len(images_np))\n",
        "\n",
        "    return (\n",
        "        SimpleDataset(images_np[:split_idx], transform=transforms['train']),\n",
        "        SimpleDataset(images_np[split_idx:], transform=transforms['val'])\n",
        "    )\n",
        "\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, dataset_path, max_class_size=500, batch_size=64, val_batch_size=16, img_size=224):\n",
        "        self.batch_size = batch_size\n",
        "        self.val_batch_size = val_batch_size\n",
        "        self.img_size = img_size\n",
        "        self.dataset_path = dataset_path\n",
        "        self.max_class_size = max_class_size\n",
        "        self.transforms = {\n",
        "            'train': transforms.Compose([\n",
        "                transforms.RandomResizedCrop(img_size),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "            ]),\n",
        "            'val': transforms.Compose([\n",
        "                transforms.Resize(img_size),\n",
        "                transforms.CenterCrop(img_size),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "            ]),\n",
        "        }\n",
        "\n",
        "        self._load_datasets()\n",
        "\n",
        "    def _load_datasets(self):\n",
        "        self.train_ds, self.val_ds = get_transformed_datasets(self.dataset_path, self.transforms, self.max_class_size)\n",
        "        self.size_dataset_train = len(self.train_ds)\n",
        "        self.size_dataset_val = len(self.val_ds)\n",
        "\n",
        "    def get_dataloader(self, train=True):\n",
        "        return DataLoader(\n",
        "            self.train_ds if train else self.val_ds,\n",
        "            batch_size=self.batch_size if train else self.val_batch_size,\n",
        "            shuffle=train,\n",
        "            num_workers=2\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size_dataset_train + self.size_dataset_val\n",
        "\n",
        "    def train_len(self):\n",
        "        return self.size_dataset_train\n",
        "\n",
        "    def val_len(self):\n",
        "        return self.size_dataset_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hp-BJn9KtXkO",
        "outputId": "ffccedb6-e40e-469e-854b-b86c7cb494c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 1/3: 100%|██████████| 200/200 [23:33<00:00,  7.07s/it, loss=0.145, acc=0.94]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1 Results:\n",
            "Train Loss: 0.3909 | Acc: 0.8411\n",
            "Val Loss: 0.1386 | Acc: 0.9400\n",
            "Saved new best model!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/3: 100%|██████████| 200/200 [00:44<00:00,  4.52it/s, loss=0.152, acc=0.94]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2 Results:\n",
            "Train Loss: 0.2676 | Acc: 0.8989\n",
            "Val Loss: 0.1088 | Acc: 0.9544\n",
            "Saved new best model!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/3: 100%|██████████| 200/200 [00:43<00:00,  4.60it/s, loss=0.343, acc=0.81]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3 Results:\n",
            "Train Loss: 0.2262 | Acc: 0.9163\n",
            "Val Loss: 0.0715 | Acc: 0.9794\n",
            "Saved new best model!\n",
            "\n",
            "Training complete! Best validation accuracy: 0.9794\n"
          ]
        }
      ],
      "source": [
        "# @title Обучение\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def train_mobilenet(dataset_path, epochs=10):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    dataset = ImageDataset(dataset_path)\n",
        "    train_loader = DataLoader(\n",
        "        dataset.get_dataloader(train=True).dataset,\n",
        "        batch_size=32,\n",
        "        shuffle=True,\n",
        "        num_workers=2\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        dataset.get_dataloader(train=False).dataset,\n",
        "        batch_size=32,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "    model = models.mobilenet_v2(weights='DEFAULT')\n",
        "    model.classifier[1] = nn.Linear(model.classifier[1].in_features, len(CLASS_TO_IDX))\n",
        "    model = model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss, train_correct = 0, 0\n",
        "\n",
        "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
        "        for inputs, labels in pbar:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            train_correct += (preds == labels).sum().item()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            pbar.set_postfix({\n",
        "                'loss': loss.item(),\n",
        "                'acc': f\"{(preds == labels).sum().item()/len(labels):.2f}\"\n",
        "            })\n",
        "\n",
        "        model.eval()\n",
        "        val_loss, val_correct = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                val_correct += (preds == labels).sum().item()\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        train_acc = train_correct / len(train_loader.dataset)\n",
        "        val_acc = val_correct / len(val_loader.dataset)\n",
        "        print(f\"\\nEpoch {epoch+1} Results:\")\n",
        "        print(f\"Train Loss: {train_loss/len(train_loader):.4f} | Acc: {train_acc:.4f}\")\n",
        "        print(f\"Val Loss: {val_loss/len(val_loader):.4f} | Acc: {val_acc:.4f}\")\n",
        "\n",
        "        # Save best model\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "            print(\"Saved new best model!\")\n",
        "\n",
        "    print(f\"\\nTraining complete! Best validation accuracy: {best_acc:.4f}\")\n",
        "\n",
        "# Run training\n",
        "if __name__ == \"__main__\":\n",
        "    train_mobilenet(DATASET_PATH, epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Da6xDJ2Z3IwM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39d7ba1a-209c-496d-ffc6-66a653ae604d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|██████████| 250/250 [26:59<00:00,  6.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation Results:\n",
            "Average Loss: 0.0610\n",
            "Overall Accuracy: 0.9856\n",
            "\n",
            "Per-class Accuracy:\n",
            "normal: 98.18% (1995/2032)\n",
            "moved: 96.19% (1967/2045)\n",
            "covered: 100.00% (1973/1973)\n",
            "defocussed: 100.00% (1950/1950)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# @title Тесты\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def load_saved_model(model_path, num_classes=4):\n",
        "    model = models.mobilenet_v2(weights=None)\n",
        "    model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
        "\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "\n",
        "def validate_model(model, val_loader, device):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    class_correct = [0] * len(CLASS_TO_IDX)\n",
        "    class_total = [0] * len(CLASS_TO_IDX)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(val_loader, desc='Validating'):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            for i in range(len(labels)):\n",
        "                label = labels[i]\n",
        "                class_correct[label] += (predicted[i] == label).item()\n",
        "                class_total[label] += 1\n",
        "\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    val_acc = correct / total\n",
        "\n",
        "    print(f'\\nValidation Results:')\n",
        "    print(f'Average Loss: {val_loss:.4f}')\n",
        "    print(f'Overall Accuracy: {val_acc:.4f}')\n",
        "\n",
        "    print('\\nPer-class Accuracy:')\n",
        "    for class_name, idx in CLASS_TO_IDX.items():\n",
        "        if class_total[idx] > 0:\n",
        "            accuracy = 100 * class_correct[idx] / class_total[idx]\n",
        "            print(f'{class_name}: {accuracy:.2f}% ({class_correct[idx]}/{class_total[idx]})')\n",
        "\n",
        "    return val_loss, val_acc\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model = load_saved_model('best_model.pth', num_classes=len(CLASS_TO_IDX))\n",
        "    model = model.to(device)\n",
        "\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    dataset = ImageDataset(DATASET_PATH, max_class_size=10000)\n",
        "    val_loader = DataLoader(\n",
        "        dataset.get_dataloader(train=False).dataset,\n",
        "        batch_size=32,\n",
        "        shuffle=False,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "    val_loss, val_acc = validate_model(model, val_loader, device)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}